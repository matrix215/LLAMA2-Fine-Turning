{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K4dOB1-9ZK2p",
        "outputId": "9b32c332-08cc-42d9-94f0-857fbedb8dba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KoChatGPT'...\n",
            "remote: Enumerating objects: 304, done.\u001b[K\n",
            "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 304 (delta 60), reused 32 (delta 31), pack-reused 192\u001b[K\n",
            "Receiving objects: 100% (304/304), 63.18 MiB | 20.89 MiB/s, done.\n",
            "Resolving deltas: 100% (119/119), done.\n",
            "/content/KoChatGPT\n",
            "Archive:  autotrain-advanced_231012.zip\n",
            "  inflating: ./autotrain-advanced_231012/examples/README.md  \n",
            "  inflating: ./autotrain-advanced_231012/examples/text_classification_binary.py  \n",
            "  inflating: ./autotrain-advanced_231012/examples/text_classification_multiclass.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/__pycache__/backend.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/__pycache__/config.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/__pycache__/dataset.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/__pycache__/logging.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/__pycache__/tasks.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/__pycache__/utils.cpython-39.pyc  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/apps/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/apps/common.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/apps/dreambooth.py  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/apps/image_classification.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/apps/llm.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/apps/main.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/apps/tabular.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/apps/text_classification.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/apps/utils.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/autotrain.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/run_api.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/run_app.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/run_dreambooth.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/run_image_classification.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/run_llm.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/run_setup.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/run_spacerunner.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/run_tabular.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__pycache__/run_text_classification.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/autotrain.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/run_api.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/run_app.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/run_dreambooth.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/run_image_classification.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/run_llm.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/run_setup.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/run_spacerunner.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/run_tabular.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/cli/run_text_classification.py  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/infer/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/infer/text_generation.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/preprocessor/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/preprocessor/__pycache__/dreambooth.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/preprocessor/__pycache__/tabular.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/preprocessor/__pycache__/text.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/preprocessor/__pycache__/vision.cpython-39.pyc  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/preprocessor/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/preprocessor/dreambooth.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/preprocessor/tabular.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/preprocessor/text.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/preprocessor/vision.py  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/tests/test_dummy.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/__pycache__/common.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/clm/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/clm/__pycache__/__main__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/clm/__pycache__/callbacks.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/clm/__pycache__/params.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/clm/__pycache__/utils.cpython-39.pyc  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/trainers/clm/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/clm/__main__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/clm/callbacks.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/clm/params.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/clm/utils.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/__pycache__/__main__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/__pycache__/datasets.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/__pycache__/params.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/__pycache__/trainer.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/__pycache__/utils.cpython-39.pyc  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/__main__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/datasets.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/params.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/trainer.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/dreambooth/utils.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/generic/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/generic/__pycache__/params.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/generic/__pycache__/utils.cpython-39.pyc  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/trainers/generic/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/generic/__main__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/generic/params.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/generic/utils.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/image_classification/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/image_classification/__pycache__/params.cpython-39.pyc  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/trainers/image_classification/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/image_classification/__main__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/image_classification/dataset.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/image_classification/params.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/image_classification/utils.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/tabular/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/tabular/__pycache__/params.cpython-39.pyc  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/trainers/tabular/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/tabular/__main__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/tabular/params.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/tabular/utils.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/text_classification/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/text_classification/__pycache__/params.cpython-39.pyc  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/trainers/text_classification/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/text_classification/__main__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/text_classification/dataset.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/text_classification/params.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/text_classification/utils.py  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/trainers/__init__.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/common.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/image_classification.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/lm_trainer.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/trainers/text_classification.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/__init__.py  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain/allowed_file_types.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/api.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/app.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/backend.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/config.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/dataset.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/dreambooth_app.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/help.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/languages.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/logging.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/params.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/project.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/splits.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/tasks.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain/utils.py  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain_advanced.egg-info/PKG-INFO  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain_advanced.egg-info/SOURCES.txt  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain_advanced.egg-info/dependency_links.txt  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain_advanced.egg-info/entry_points.txt  \n",
            "  inflating: ./autotrain-advanced_231012/src/autotrain_advanced.egg-info/requires.txt  \n",
            " extracting: ./autotrain-advanced_231012/src/autotrain_advanced.egg-info/top_level.txt  \n",
            "  inflating: ./autotrain-advanced_231012/.dockerignore  \n",
            "  inflating: ./autotrain-advanced_231012/.gitignore  \n",
            "  inflating: ./autotrain-advanced_231012/Dockerfile  \n",
            "  inflating: ./autotrain-advanced_231012/LICENSE  \n",
            "  inflating: ./autotrain-advanced_231012/Makefile  \n",
            "  inflating: ./autotrain-advanced_231012/README.md  \n",
            "  inflating: ./autotrain-advanced_231012/requirements.txt  \n",
            "  inflating: ./autotrain-advanced_231012/setup.cfg  \n",
            "  inflating: ./autotrain-advanced_231012/setup.py  \n",
            "/content/KoChatGPT/autotrain-advanced_231012\n",
            "Obtaining file:///content/KoChatGPT/autotrain-advanced_231012\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: albumentations==1.3.1 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.36.dev0) (1.3.1)\n",
            "Collecting codecarbon==2.2.3 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading codecarbon-2.2.3-py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/174.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets[vision]~=2.14.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate==0.3.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipadic==1.0.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jiwer==3.0.2 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading jiwer-3.0.2-py3-none-any.whl (21 kB)\n",
            "Collecting joblib==1.3.1 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting loguru==0.7.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.36.dev0) (1.5.3)\n",
            "Collecting optuna==3.3.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==10.0.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading Pillow-10.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==4.23.4 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic==1.10.11 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading pydantic-1.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses==0.0.53 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit-learn==1.3.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece==0.1.99 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.36.dev0) (0.1.99)\n",
            "Collecting tqdm==4.65.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug==2.3.6 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xgboost==1.7.6 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface_hub>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.36.dev0) (0.20.3)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.36.dev0) (2.31.0)\n",
            "Collecting gradio==3.41.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading gradio-3.41.0-py3-none-any.whl (20.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops==0.6.1 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting invisible-watermark==0.2.0 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging==23.1 (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.36.dev0) (2.15.2)\n",
            "Collecting peft (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading peft-0.8.2-py3-none-any.whl (183 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trl (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading trl-0.7.11-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.36.dev0) (4.37.2)\n",
            "Collecting accelerate (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diffusers (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading diffusers-0.26.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes (from autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced==0.6.36.dev0) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced==0.6.36.dev0) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced==0.6.36.dev0) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced==0.6.36.dev0) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced==0.6.36.dev0) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced==0.6.36.dev0) (4.9.0.80)\n",
            "Collecting arrow (from codecarbon==2.2.3->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynvml (from codecarbon==2.2.3->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced==0.6.36.dev0) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced==0.6.36.dev0) (9.0.0)\n",
            "Collecting fuzzywuzzy (from codecarbon==2.2.3->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced==0.6.36.dev0) (8.1.7)\n",
            "Collecting datasets>=2.0.0 (from evaluate==0.3.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading datasets-2.17.1-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from evaluate==0.3.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->autotrain-advanced==0.6.36.dev0) (3.4.1)\n",
            "Collecting multiprocess (from evaluate==0.3.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->autotrain-advanced==0.6.36.dev0) (2023.6.0)\n",
            "Collecting responses<0.19 (from evaluate==0.3.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (4.2.2)\n",
            "Collecting fastapi (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.5.0 (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading gradio_client-0.5.0-py3-none-any.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (4.9.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced==0.6.36.dev0) (1.5.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced==0.6.36.dev0) (4.8.0.76)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced==0.6.36.dev0) (2.1.0+cu121)\n",
            "Collecting rapidfuzz==2.13.7 (from jiwer==3.0.2->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading rapidfuzz-2.13.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna==3.3.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.10.0 (from optuna==3.3.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
            "Collecting colorlog (from optuna==3.3.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna==3.3.0->autotrain-advanced==0.6.36.dev0) (2.0.27)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced==0.6.36.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced==0.6.36.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced==0.6.36.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced==0.6.36.dev0) (2024.2.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.53->autotrain-advanced==0.6.36.dev0) (2023.12.25)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.53->autotrain-advanced==0.6.36.dev0) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.0->autotrain-advanced==0.6.36.dev0) (3.3.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets[vision]~=2.14.0->autotrain-advanced==0.6.36.dev0) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets[vision]~=2.14.0->autotrain-advanced==0.6.36.dev0) (0.6)\n",
            "Collecting dill (from evaluate==0.3.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets[vision]~=2.14.0->autotrain-advanced==0.6.36.dev0) (3.9.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.16.4->autotrain-advanced==0.6.36.dev0) (3.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->autotrain-advanced==0.6.36.dev0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->autotrain-advanced==0.6.36.dev0) (2023.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate->autotrain-advanced==0.6.36.dev0) (0.4.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers->autotrain-advanced==0.6.36.dev0) (7.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.36.dev0) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.36.dev0) (1.60.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.36.dev0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.36.dev0) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.36.dev0) (3.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.36.dev0) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.36.dev0) (0.7.2)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->autotrain-advanced==0.6.36.dev0) (0.15.2)\n",
            "Collecting tyro>=0.5.11 (from trl->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading tyro-0.7.3-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Mako (from alembic>=1.5.0->optuna==3.3.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (0.12.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced==0.6.36.dev0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced==0.6.36.dev0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced==0.6.36.dev0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced==0.6.36.dev0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced==0.6.36.dev0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced==0.6.36.dev0) (4.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced==0.6.36.dev0) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced==0.6.36.dev0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced==0.6.36.dev0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->autotrain-advanced==0.6.36.dev0) (1.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (3.1.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->autotrain-advanced==0.6.36.dev0) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->autotrain-advanced==0.6.36.dev0) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->autotrain-advanced==0.6.36.dev0) (2024.2.12)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna==3.3.0->autotrain-advanced==0.6.36.dev0) (3.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->invisible-watermark==0.2.0->autotrain-advanced==0.6.36.dev0) (1.12)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->invisible-watermark==0.2.0->autotrain-advanced==0.6.36.dev0) (2.1.0)\n",
            "Collecting docstring-parser>=0.14.1 (from tyro>=0.5.11->trl->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl->autotrain-advanced==0.6.36.dev0) (13.7.0)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading shtab-1.7.0-py3-none-any.whl (14 kB)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-python-dateutil>=2.8.10 (from arrow->codecarbon==2.2.3->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading types_python_dateutil-2.8.19.20240106-py3-none-any.whl (9.7 kB)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->gradio==3.41.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers->autotrain-advanced==0.6.36.dev0) (3.17.0)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from evaluate==0.3.0->autotrain-advanced==0.6.36.dev0)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (0.18.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->autotrain-advanced==0.6.36.dev0) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->autotrain-advanced==0.6.36.dev0) (3.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl->autotrain-advanced==0.6.36.dev0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl->autotrain-advanced==0.6.36.dev0) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==3.41.0->autotrain-advanced==0.6.36.dev0) (1.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->invisible-watermark==0.2.0->autotrain-advanced==0.6.36.dev0) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl->autotrain-advanced==0.6.36.dev0) (0.1.2)\n",
            "Building wheels for collected packages: ipadic, sacremoses, ffmpy\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556704 sha256=56e21678417cef5e67e981bb0d0ea05d2de676bc8bf8fbe065705c56b2130b2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/ea/e3/2f6e0860a327daba3b030853fce4483ed37468bbf1101c59c3\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895239 sha256=d52daaa512dbdb1b164e7277d609758546fc119a61028bd85eb2b0c28406b074\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=6642004e12ccc8ea9806d97a3057b3c7fb5661556314b287a8c03c6452b06295\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ipadic sacremoses ffmpy\n",
            "Installing collected packages: pydub, ipadic, fuzzywuzzy, ffmpy, werkzeug, websockets, types-python-dateutil, tqdm, shtab, semantic-version, rapidfuzz, python-multipart, pynvml, pydantic, protobuf, Pillow, packaging, orjson, Mako, loguru, joblib, h11, einops, docstring-parser, dill, colorlog, cmaes, aiofiles, xgboost, uvicorn, tiktoken, starlette, scikit-learn, sacremoses, responses, multiprocess, jiwer, httpcore, bitsandbytes, arrow, alembic, tyro, optuna, invisible-watermark, httpx, fastapi, diffusers, codecarbon, accelerate, gradio-client, datasets, trl, peft, gradio, evaluate, autotrain-advanced\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.0.1\n",
            "    Uninstalling Werkzeug-3.0.1:\n",
            "      Successfully uninstalled Werkzeug-3.0.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.2\n",
            "    Uninstalling tqdm-4.66.2:\n",
            "      Successfully uninstalled tqdm-4.66.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.1\n",
            "    Uninstalling pydantic-2.6.1:\n",
            "      Successfully uninstalled pydantic-2.6.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.2\n",
            "    Uninstalling packaging-23.2:\n",
            "      Successfully uninstalled packaging-23.2\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.3.2\n",
            "    Uninstalling joblib-1.3.2:\n",
            "      Successfully uninstalled joblib-1.3.2\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.0.3\n",
            "    Uninstalling xgboost-2.0.3:\n",
            "      Successfully uninstalled xgboost-2.0.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Running setup.py develop for autotrain-advanced\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.2 Pillow-10.0.0 accelerate-0.27.2 aiofiles-23.2.1 alembic-1.13.1 arrow-1.3.0 autotrain-advanced-0.6.36.dev0 bitsandbytes-0.42.0 cmaes-0.10.0 codecarbon-2.2.3 colorlog-6.8.2 datasets-2.14.7 diffusers-0.26.3 dill-0.3.7 docstring-parser-0.15 einops-0.6.1 evaluate-0.3.0 fastapi-0.110.0 ffmpy-0.3.2 fuzzywuzzy-0.18.0 gradio-3.41.0 gradio-client-0.5.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 invisible-watermark-0.2.0 ipadic-1.0.0 jiwer-3.0.2 joblib-1.3.1 loguru-0.7.0 multiprocess-0.70.15 optuna-3.3.0 orjson-3.9.15 packaging-23.1 peft-0.8.2 protobuf-4.23.4 pydantic-1.10.11 pydub-0.25.1 pynvml-11.5.0 python-multipart-0.0.9 rapidfuzz-2.13.7 responses-0.18.0 sacremoses-0.0.53 scikit-learn-1.3.0 semantic-version-2.10.0 shtab-1.7.0 starlette-0.36.3 tiktoken-0.6.0 tqdm-4.65.0 trl-0.7.11 types-python-dateutil-2.8.19.20240106 tyro-0.7.3 uvicorn-0.27.1 websockets-11.0.3 werkzeug-2.3.6 xgboost-1.7.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 에러없는 과거버전 autotrain으로 설치\n",
        "!git clone https://github.com/airobotlab/KoChatGPT.git\n",
        "%cd ./KoChatGPT\n",
        "!unzip autotrain-advanced_231012 -d ./autotrain-advanced_231012\n",
        "%cd ./autotrain-advanced_231012\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data\n",
        "description = 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.'\n",
        "지시 = 'Identify the odd one out.'\n",
        "입력 = 'Twitter, Instagram, Telegram'\n",
        "출력 = 'Telegram'\n",
        "\n",
        "text = f'{description}\\n### Instruction: {지시}\\n### Input: {입력}\\n### Response: {출력}'\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kibxpPjwZvXy",
        "outputId": "9d7c5dee-025d-472e-da96-fac37185f802"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "### Instruction: Identify the odd one out.\n",
            "### Input: Twitter, Instagram, Telegram\n",
            "### Response: Telegram\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_data = [\n",
        "    {\"text\": text},\n",
        "    {\"text\": text},\n",
        "    {\"text\": text}\n",
        "]\n",
        "\n",
        "custom_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHbN5cikZzQt",
        "outputId": "67f70c43-c9f3-4d92-b6f3-3d2e861792d1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n### Instruction: Identify the odd one out.\\n### Input: Twitter, Instagram, Telegram\\n### Response: Telegram'},\n",
              " {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n### Instruction: Identify the odd one out.\\n### Input: Twitter, Instagram, Telegram\\n### Response: Telegram'},\n",
              " {'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n### Instruction: Identify the odd one out.\\n### Input: Twitter, Instagram, Telegram\\n### Response: Telegram'}]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data\n",
        "description = 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.'\n",
        "\n",
        "\n",
        "지시 = 'Identify the odd one out.'\n",
        "입력 = 'Twitter, Instagram, Telegram'\n",
        "출력 = 'Telegram'\n",
        "\n",
        "text = f'{description}\\n### Instruction: {지시}\\n### Input: {입력}\\n### Response: {출력}'\n",
        "print(text)\n",
        "\n",
        "\n",
        "\n",
        "custom_data = [\n",
        "    {\"text\": \"### Human: Can you write a short introduction about the relevance of the term \\\"monopsony\\\" in economics? Please use examples related to\"},\n",
        "    {\"text\": \"### Human: Can you write a short introduction about the relevance of the term \\\"monopsony\\\" in economics? Please use examples related to\"},\n",
        "    {\"text\": \"### Human: Can you write a short introduction about the relevance of the term \\\"monopsony\\\" in economics? Please use examples related to\"}\n",
        "]\n",
        "\n",
        "# 위에서 설정한 학습 데이터를 파일로 저장합니다.\n",
        "import json\n",
        "with open(\"custom_data.jsonl\", \"w\", encoding='utf-8') as json_file:\n",
        "    json.dump(custom_data, json_file, indent=4, ensure_ascii=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDX_6R4NZ0Xl",
        "outputId": "911c14a2-d178-4441-96a5-3d389b2991e8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "### Instruction: Identify the odd one out.\n",
            "### Input: Twitter, Instagram, Telegram\n",
            "### Response: Telegram\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# single line command!\n",
        "# \"quantumaikr/KoreanLM-llama-2-7B-finetuned\"  # 한국어\n",
        "# \"TinyPixel/Llama-2-7B-bf16-sharded\"  # 영어\n",
        "\n",
        "project_name='test'\n",
        "model = 'TinyPixel/Llama-2-7B-bf16-sharded'\n",
        "data_path = 'timdettmers/openassistant-guanaco'\n",
        "# data_path = 'tatsu-lab/alpaca'\n",
        "\n",
        "train_batch_size = 2\n",
        "num_train_epochs = 2\n",
        "model_max_length = 2048\n",
        "repo_id = 'keepsteady/test'\n",
        "\n",
        "cmd = f'''autotrain llm --train --project_name {project_name} \\\n",
        "                    --model {model} \\\n",
        "                    --data_path {data_path} \\\n",
        "                    --text_column \\\"text\\\" \\\n",
        "                    --use_peft \\\n",
        "                    --use_int4 \\\n",
        "                    --learning_rate 2e-4 \\\n",
        "                    --train_batch_size {train_batch_size} \\\n",
        "                    --num_train_epochs {num_train_epochs} \\\n",
        "                    --trainer sft \\\n",
        "                    --model_max_length {model_max_length} \\\n",
        "                    --push_to_hub \\\n",
        "                    --repo_id {repo_id} \\\n",
        "                    --block_size 2048'''\n",
        "\n",
        "print(cmd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6eON5HHZ2my",
        "outputId": "d915804e-c9a9-4bfe-b9c4-1d277a4fee15"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "autotrain llm --train --project_name test                     --model TinyPixel/Llama-2-7B-bf16-sharded                     --data_path timdettmers/openassistant-guanaco                     --text_column \"text\"                     --use_peft                     --use_int4                     --learning_rate 2e-4                     --train_batch_size 2                     --num_train_epochs 2                     --trainer sft                     --model_max_length 2048                     --push_to_hub                     --repo_id keepsteady/test                     --block_size 2048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!autotrain llm --train --project_name test                     --model TinyPixel/Llama-2-7B-bf16-sharded                     --data_path timdettmers/openassistant-guanaco                     --text_column \"text\" \\--use_peft                     --use_int4                     --learning_rate 2e-4                     --train_batch_size 2                     --num_train_epochs 2                     --trainer sft                     --model_max_length 2048                     --push_to_hub                     --repo_id keepsteady/test                     --block_size 2048"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55_oEQvdZ4qR",
        "outputId": "973376ea-4f46-4bdc-8bb4-fe300a28484a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\u001b[1m⚠️ WARNING\u001b[0m | \u001b[32m2024-02-25 04:00:05\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m14\u001b[0m - \u001b[33m\u001b[1m❌ Some DreamBooth components are missing! Please run `autotrain setup` to install it. Ignore this warning if you are not using DreamBooth or running `autotrain setup` already.\u001b[0m\n",
            "> \u001b[1mINFO    Running LLM\u001b[0m\n",
            "> \u001b[1mINFO    Params: Namespace(version=False, train=True, deploy=False, inference=False, data_path='timdettmers/openassistant-guanaco', train_split='train', valid_split=None, text_column='text', model='TinyPixel/Llama-2-7B-bf16-sharded', learning_rate=0.0002, num_train_epochs=2, train_batch_size=2, warmup_ratio=0.1, gradient_accumulation_steps=1, optimizer='adamw_torch', scheduler='linear', weight_decay=0.0, max_grad_norm=1.0, seed=42, add_eos_token=False, block_size=2048, use_peft=True, lora_r=16, lora_alpha=32, lora_dropout=0.05, logging_steps=-1, project_name='test', evaluation_strategy='epoch', save_total_limit=1, save_strategy='epoch', auto_find_batch_size=False, fp16=False, push_to_hub=True, use_int8=False, model_max_length=2048, repo_id='keepsteady/test', use_int4=True, trainer='sft', target_modules=None, merge_adapter=False, token=None, backend='default', username=None, use_flash_attention_2=False, func=<function run_llm_command_factory at 0x7c7cd4f99480>)\u001b[0m\n",
            "Downloading readme: 100% 395/395 [00:00<00:00, 3.05MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
            "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n",
            "Downloading data files:   0% 0/2 [00:00<?, ?it/s]\n",
            "Downloading data:   0% 0.00/20.9M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:  20% 4.19M/20.9M [00:00<00:01, 9.85MB/s]\u001b[A\n",
            "Downloading data:  60% 12.6M/20.9M [00:00<00:00, 19.3MB/s]\u001b[A\n",
            "Downloading data: 100% 20.9M/20.9M [00:00<00:00, 22.0MB/s]\n",
            "Downloading data files:  50% 1/2 [00:00<00:00,  1.05it/s]\n",
            "Downloading data:   0% 0.00/1.11M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data: 100% 1.11M/1.11M [00:00<00:00, 4.78MB/s]\n",
            "Downloading data files: 100% 2/2 [00:01<00:00,  1.69it/s]\n",
            "Extracting data files: 100% 2/2 [00:00<00:00, 2089.32it/s]\n",
            "Generating train split: 9846 examples [00:00, 70173.64 examples/s]\n",
            "Generating test split: 518 examples [00:00, 76225.29 examples/s]\n",
            "tokenizer_config.json: 100% 676/676 [00:00<00:00, 4.15MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 482MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 5.55MB/s]\n",
            "special_tokens_map.json: 100% 411/411 [00:00<00:00, 2.10MB/s]\n",
            "config.json: 100% 626/626 [00:00<00:00, 3.79MB/s]\n",
            "model.safetensors.index.json: 100% 28.1k/28.1k [00:00<00:00, 118MB/s]\n",
            "Downloading shards:   0% 0/14 [00:00<?, ?it/s]\n",
            "model-00001-of-00014.safetensors:   0% 0.00/981M [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:   3% 31.5M/981M [00:00<00:04, 233MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:   6% 62.9M/981M [00:00<00:03, 244MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  10% 94.4M/981M [00:00<00:03, 252MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  13% 126M/981M [00:00<00:03, 232MB/s] \u001b[A\n",
            "model-00001-of-00014.safetensors:  16% 157M/981M [00:00<00:03, 224MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  19% 189M/981M [00:00<00:03, 204MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  21% 210M/981M [00:00<00:03, 205MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  24% 231M/981M [00:01<00:03, 194MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  27% 262M/981M [00:01<00:03, 211MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  30% 294M/981M [00:01<00:03, 212MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  33% 325M/981M [00:01<00:02, 221MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  36% 357M/981M [00:01<00:02, 228MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  40% 388M/981M [00:01<00:02, 237MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  43% 419M/981M [00:01<00:02, 222MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  46% 451M/981M [00:02<00:02, 215MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  49% 482M/981M [00:02<00:02, 211MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  52% 514M/981M [00:02<00:02, 213MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  56% 545M/981M [00:04<00:10, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  59% 577M/981M [00:04<00:07, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  61% 598M/981M [00:04<00:05, 66.9MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  63% 619M/981M [00:04<00:04, 73.4MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  65% 640M/981M [00:05<00:03, 85.8MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  67% 661M/981M [00:05<00:03, 99.8MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  69% 682M/981M [00:05<00:02, 115MB/s] \u001b[A\n",
            "model-00001-of-00014.safetensors:  72% 703M/981M [00:05<00:02, 132MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  74% 724M/981M [00:05<00:01, 133MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  76% 744M/981M [00:05<00:01, 140MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  79% 776M/981M [00:05<00:01, 162MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  82% 807M/981M [00:05<00:00, 179MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  85% 839M/981M [00:06<00:00, 190MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  88% 860M/981M [00:06<00:00, 184MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  90% 881M/981M [00:06<00:00, 180MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  92% 902M/981M [00:06<00:00, 178MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  94% 923M/981M [00:06<00:00, 180MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  96% 944M/981M [00:06<00:00, 181MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors: 100% 981M/981M [00:08<00:00, 117MB/s]\n",
            "Downloading shards:   7% 1/14 [00:08<01:50,  8.52s/it]\n",
            "model-00002-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:   2% 21.0M/967M [00:00<00:05, 186MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:   5% 52.4M/967M [00:00<00:03, 231MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:   9% 83.9M/967M [00:00<00:03, 241MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  12% 115M/967M [00:00<00:03, 221MB/s] \u001b[A\n",
            "model-00002-of-00014.safetensors:  15% 147M/967M [00:00<00:03, 212MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  18% 178M/967M [00:00<00:04, 183MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  22% 210M/967M [00:01<00:03, 197MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  25% 241M/967M [00:01<00:03, 212MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  28% 273M/967M [00:01<00:03, 212MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  31% 304M/967M [00:01<00:02, 224MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  35% 336M/967M [00:01<00:02, 226MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  38% 367M/967M [00:01<00:02, 208MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  41% 398M/967M [00:01<00:02, 205MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  43% 419M/967M [00:01<00:02, 206MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  47% 451M/967M [00:02<00:02, 211MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  50% 482M/967M [00:02<00:02, 222MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  53% 514M/967M [00:02<00:01, 231MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  56% 545M/967M [00:02<00:01, 233MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  60% 577M/967M [00:02<00:01, 221MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  63% 608M/967M [00:02<00:01, 216MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  66% 640M/967M [00:02<00:01, 220MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  69% 671M/967M [00:05<00:09, 31.9MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  73% 703M/967M [00:06<00:06, 43.1MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  76% 734M/967M [00:06<00:04, 55.2MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  78% 755M/967M [00:06<00:03, 62.8MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  80% 776M/967M [00:06<00:02, 73.4MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  84% 807M/967M [00:06<00:01, 94.7MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  87% 839M/967M [00:06<00:01, 115MB/s] \u001b[A\n",
            "model-00002-of-00014.safetensors:  89% 860M/967M [00:06<00:00, 128MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  92% 891M/967M [00:07<00:00, 151MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  95% 923M/967M [00:07<00:00, 166MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors: 100% 967M/967M [00:07<00:00, 130MB/s]\n",
            "Downloading shards:  14% 2/14 [00:16<01:35,  7.96s/it]\n",
            "model-00003-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:   2% 21.0M/967M [00:00<00:05, 178MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:   5% 52.4M/967M [00:00<00:04, 206MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:   9% 83.9M/967M [00:00<00:04, 214MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  12% 115M/967M [00:00<00:03, 226MB/s] \u001b[A\n",
            "model-00003-of-00014.safetensors:  15% 147M/967M [00:00<00:04, 199MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  17% 168M/967M [00:00<00:04, 195MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  20% 189M/967M [00:00<00:04, 189MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  22% 210M/967M [00:01<00:04, 185MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  24% 231M/967M [00:01<00:04, 184MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  26% 252M/967M [00:03<00:24, 29.6MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  28% 273M/967M [00:03<00:17, 39.6MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  31% 304M/967M [00:03<00:11, 58.1MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  35% 336M/967M [00:03<00:07, 79.3MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  38% 367M/967M [00:03<00:06, 98.8MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  40% 388M/967M [00:04<00:05, 101MB/s] \u001b[A\n",
            "model-00003-of-00014.safetensors:  42% 409M/967M [00:04<00:04, 115MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  46% 440M/967M [00:04<00:03, 139MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  48% 461M/967M [00:04<00:03, 147MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  50% 482M/967M [00:04<00:03, 156MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  52% 503M/967M [00:04<00:04, 115MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  54% 524M/967M [00:04<00:03, 131MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  57% 556M/967M [00:05<00:02, 159MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  61% 587M/967M [00:05<00:02, 179MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  63% 608M/967M [00:05<00:01, 179MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  65% 629M/967M [00:05<00:01, 184MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  67% 650M/967M [00:05<00:01, 189MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  70% 682M/967M [00:05<00:01, 195MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  73% 703M/967M [00:05<00:01, 198MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  75% 724M/967M [00:05<00:01, 199MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  78% 755M/967M [00:06<00:01, 207MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  81% 786M/967M [00:06<00:00, 220MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  85% 818M/967M [00:06<00:00, 223MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  88% 849M/967M [00:06<00:00, 193MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  90% 870M/967M [00:06<00:00, 181MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  92% 891M/967M [00:06<00:00, 180MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  94% 912M/967M [00:06<00:00, 182MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  98% 944M/967M [00:07<00:00, 192MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors: 100% 967M/967M [00:08<00:00, 117MB/s] \n",
            "Downloading shards:  21% 3/14 [00:24<01:29,  8.17s/it]\n",
            "model-00004-of-00014.safetensors:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:   2% 21.0M/990M [00:00<00:08, 108MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:   4% 41.9M/990M [00:00<00:06, 142MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:   7% 73.4M/990M [00:00<00:05, 182MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  11% 105M/990M [00:00<00:04, 203MB/s] \u001b[A\n",
            "model-00004-of-00014.safetensors:  14% 136M/990M [00:00<00:03, 219MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  17% 168M/990M [00:00<00:03, 213MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  20% 199M/990M [00:01<00:03, 203MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  22% 220M/990M [00:01<00:03, 202MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  25% 252M/990M [00:01<00:03, 208MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  29% 283M/990M [00:01<00:03, 211MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  32% 315M/990M [00:01<00:03, 217MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  35% 346M/990M [00:01<00:02, 216MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  38% 377M/990M [00:01<00:02, 223MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  41% 409M/990M [00:01<00:02, 224MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  44% 440M/990M [00:02<00:02, 221MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  48% 472M/990M [00:02<00:02, 230MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  51% 503M/990M [00:02<00:02, 234MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  54% 535M/990M [00:02<00:01, 237MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  57% 566M/990M [00:02<00:01, 219MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  60% 598M/990M [00:02<00:01, 217MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  64% 629M/990M [00:02<00:01, 218MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  67% 661M/990M [00:04<00:07, 45.2MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  70% 692M/990M [00:05<00:05, 58.5MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  72% 713M/990M [00:05<00:04, 65.6MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  74% 734M/990M [00:05<00:03, 75.1MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  77% 765M/990M [00:05<00:02, 97.2MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  81% 797M/990M [00:05<00:01, 120MB/s] \u001b[A\n",
            "model-00004-of-00014.safetensors:  83% 818M/990M [00:05<00:01, 128MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  85% 839M/990M [00:05<00:01, 141MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  88% 870M/990M [00:06<00:00, 162MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  91% 902M/990M [00:06<00:00, 177MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  94% 933M/990M [00:06<00:00, 192MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  97% 965M/990M [00:06<00:00, 202MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors: 100% 990M/990M [00:06<00:00, 149MB/s]\n",
            "Downloading shards:  29% 4/14 [00:31<01:16,  7.61s/it]\n",
            "model-00005-of-00014.safetensors:   0% 0.00/944M [00:00<?, ?B/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:   3% 31.5M/944M [00:00<00:03, 254MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:   7% 62.9M/944M [00:00<00:03, 247MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  10% 94.4M/944M [00:00<00:03, 251MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  13% 126M/944M [00:00<00:03, 242MB/s] \u001b[A\n",
            "model-00005-of-00014.safetensors:  17% 157M/944M [00:00<00:03, 221MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  20% 189M/944M [00:00<00:03, 219MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  23% 220M/944M [00:00<00:03, 217MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  27% 252M/944M [00:03<00:19, 35.7MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  30% 283M/944M [00:03<00:13, 48.8MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  33% 315M/944M [00:03<00:09, 64.7MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  37% 346M/944M [00:03<00:07, 83.6MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  40% 377M/944M [00:03<00:05, 104MB/s] \u001b[A\n",
            "model-00005-of-00014.safetensors:  43% 409M/944M [00:04<00:04, 118MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  46% 430M/944M [00:04<00:04, 127MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  49% 461M/944M [00:04<00:03, 147MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  52% 493M/944M [00:04<00:02, 165MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  56% 524M/944M [00:04<00:02, 178MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  59% 556M/944M [00:04<00:02, 164MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  61% 577M/944M [00:05<00:02, 169MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  63% 598M/944M [00:05<00:01, 177MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  67% 629M/944M [00:05<00:01, 195MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  70% 661M/944M [00:05<00:01, 203MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  73% 692M/944M [00:05<00:01, 195MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  76% 713M/944M [00:05<00:01, 197MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  78% 734M/944M [00:05<00:01, 199MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  80% 755M/944M [00:05<00:00, 198MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  82% 776M/944M [00:07<00:04, 33.7MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  86% 807M/944M [00:07<00:02, 49.5MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  89% 839M/944M [00:08<00:01, 68.0MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  92% 870M/944M [00:08<00:00, 89.4MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  96% 902M/944M [00:08<00:00, 108MB/s] \u001b[A\n",
            "model-00005-of-00014.safetensors: 100% 944M/944M [00:08<00:00, 109MB/s]\n",
            "Downloading shards:  36% 5/14 [00:39<01:12,  8.02s/it]\n",
            "model-00006-of-00014.safetensors:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:   2% 21.0M/990M [00:00<00:04, 201MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:   4% 41.9M/990M [00:00<00:04, 200MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:   7% 73.4M/990M [00:00<00:04, 210MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  10% 94.4M/990M [00:00<00:04, 199MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  12% 115M/990M [00:00<00:05, 172MB/s] \u001b[A\n",
            "model-00006-of-00014.safetensors:  14% 136M/990M [00:00<00:05, 168MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  16% 157M/990M [00:00<00:05, 163MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  18% 178M/990M [00:01<00:05, 162MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  20% 199M/990M [00:01<00:04, 165MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  22% 220M/990M [00:01<00:04, 168MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  24% 241M/990M [00:01<00:04, 177MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  26% 262M/990M [00:01<00:04, 178MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  30% 294M/990M [00:01<00:03, 189MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  33% 325M/990M [00:01<00:03, 198MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  35% 346M/990M [00:01<00:03, 185MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  37% 367M/990M [00:02<00:03, 175MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  39% 388M/990M [00:02<00:03, 168MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  41% 409M/990M [00:02<00:03, 169MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  43% 430M/990M [00:02<00:03, 171MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  46% 451M/990M [00:04<00:15, 34.3MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  48% 472M/990M [00:04<00:11, 43.7MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  50% 493M/990M [00:04<00:08, 55.7MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  52% 514M/990M [00:04<00:06, 68.5MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  54% 535M/990M [00:04<00:05, 79.5MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  57% 566M/990M [00:04<00:03, 108MB/s] \u001b[A\n",
            "model-00006-of-00014.safetensors:  59% 587M/990M [00:05<00:03, 122MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  61% 608M/990M [00:05<00:02, 130MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  64% 629M/990M [00:05<00:02, 143MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  66% 650M/990M [00:05<00:02, 143MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  68% 671M/990M [00:05<00:02, 154MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  71% 703M/990M [00:05<00:01, 181MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  74% 734M/990M [00:05<00:01, 188MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  76% 755M/990M [00:05<00:01, 192MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  78% 776M/990M [00:06<00:02, 79.3MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  81% 797M/990M [00:06<00:02, 91.1MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  84% 828M/990M [00:06<00:01, 117MB/s] \u001b[A\n",
            "model-00006-of-00014.safetensors:  87% 860M/990M [00:07<00:00, 141MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  90% 891M/990M [00:07<00:00, 164MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  93% 923M/990M [00:07<00:00, 173MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  95% 944M/990M [00:07<00:00, 174MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  97% 965M/990M [00:07<00:00, 181MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors: 100% 990M/990M [00:07<00:00, 128MB/s]\n",
            "Downloading shards:  43% 6/14 [00:47<01:03,  7.95s/it]\n",
            "model-00007-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:   2% 21.0M/967M [00:00<00:07, 127MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:   4% 41.9M/967M [00:01<00:35, 25.7MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:   5% 52.4M/967M [00:01<00:27, 33.0MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:   8% 73.4M/967M [00:01<00:17, 52.0MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  10% 94.4M/967M [00:01<00:11, 73.3MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  13% 126M/967M [00:01<00:07, 107MB/s]  \u001b[A\n",
            "model-00007-of-00014.safetensors:  16% 157M/967M [00:02<00:05, 138MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  20% 189M/967M [00:02<00:05, 155MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  22% 210M/967M [00:02<00:04, 154MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  24% 231M/967M [00:02<00:04, 163MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  27% 262M/967M [00:02<00:03, 181MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  30% 294M/967M [00:02<00:03, 195MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  34% 325M/967M [00:02<00:03, 206MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  37% 357M/967M [00:02<00:02, 211MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  40% 388M/967M [00:03<00:02, 220MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  43% 419M/967M [00:03<00:02, 213MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  47% 451M/967M [00:03<00:02, 209MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  50% 482M/967M [00:03<00:02, 211MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  53% 514M/967M [00:04<00:04, 107MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  56% 545M/967M [00:04<00:03, 129MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  59% 566M/967M [00:04<00:02, 137MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  61% 587M/967M [00:04<00:02, 132MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  63% 608M/967M [00:04<00:02, 140MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  65% 629M/967M [00:04<00:02, 153MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  67% 650M/967M [00:04<00:02, 158MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  69% 671M/967M [00:05<00:02, 147MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  72% 692M/967M [00:05<00:01, 150MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  74% 713M/967M [00:05<00:01, 154MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  76% 734M/967M [00:06<00:04, 55.6MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  78% 755M/967M [00:06<00:03, 69.8MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  80% 776M/967M [00:06<00:02, 84.0MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  82% 797M/967M [00:06<00:01, 101MB/s] \u001b[A\n",
            "model-00007-of-00014.safetensors:  85% 818M/967M [00:07<00:01, 88.9MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  88% 849M/967M [00:07<00:00, 118MB/s] \u001b[A\n",
            "model-00007-of-00014.safetensors:  91% 881M/967M [00:07<00:00, 143MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  93% 902M/967M [00:07<00:00, 151MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  95% 923M/967M [00:07<00:00, 157MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  98% 944M/967M [00:07<00:00, 168MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors: 100% 967M/967M [00:07<00:00, 124MB/s]\n",
            "Downloading shards:  50% 7/14 [00:55<00:55,  7.93s/it]\n",
            "model-00008-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:   3% 31.5M/967M [00:00<00:03, 239MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:   7% 62.9M/967M [00:00<00:03, 234MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  10% 94.4M/967M [00:00<00:03, 229MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  13% 126M/967M [00:00<00:04, 197MB/s] \u001b[A\n",
            "model-00008-of-00014.safetensors:  15% 147M/967M [00:00<00:04, 190MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  17% 168M/967M [00:00<00:04, 187MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  21% 199M/967M [00:00<00:03, 198MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  24% 231M/967M [00:01<00:03, 203MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  26% 252M/967M [00:03<00:22, 31.3MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  29% 283M/967M [00:03<00:15, 44.5MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  31% 304M/967M [00:03<00:13, 50.1MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  34% 325M/967M [00:04<00:10, 62.3MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  37% 357M/967M [00:04<00:07, 83.4MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  40% 388M/967M [00:04<00:05, 106MB/s] \u001b[A\n",
            "model-00008-of-00014.safetensors:  42% 409M/967M [00:04<00:04, 116MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  44% 430M/967M [00:04<00:04, 128MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  48% 461M/967M [00:04<00:03, 149MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  51% 493M/967M [00:04<00:02, 170MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  54% 524M/967M [00:04<00:02, 187MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  57% 556M/967M [00:05<00:02, 204MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  61% 587M/967M [00:05<00:01, 200MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  64% 619M/967M [00:05<00:01, 194MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  66% 640M/967M [00:05<00:01, 196MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  68% 661M/967M [00:05<00:01, 199MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  72% 692M/967M [00:08<00:09, 29.2MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  74% 713M/967M [00:08<00:06, 36.7MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  76% 734M/967M [00:08<00:05, 45.7MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  78% 755M/967M [00:08<00:03, 56.0MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  80% 776M/967M [00:09<00:02, 68.8MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  82% 797M/967M [00:09<00:02, 84.4MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  85% 818M/967M [00:09<00:01, 102MB/s] \u001b[A\n",
            "model-00008-of-00014.safetensors:  87% 839M/967M [00:09<00:01, 115MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  89% 860M/967M [00:09<00:00, 114MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  91% 881M/967M [00:09<00:00, 125MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  94% 912M/967M [00:09<00:00, 150MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  98% 944M/967M [00:09<00:00, 166MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors: 100% 967M/967M [00:10<00:00, 96.0MB/s]\n",
            "Downloading shards:  57% 8/14 [01:05<00:51,  8.65s/it]\n",
            "model-00009-of-00014.safetensors:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:   2% 21.0M/990M [00:00<00:06, 156MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:   4% 41.9M/990M [00:00<00:05, 163MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:   6% 62.9M/990M [00:00<00:05, 166MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:   8% 83.9M/990M [00:00<00:05, 168MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  11% 105M/990M [00:00<00:05, 174MB/s] \u001b[A\n",
            "model-00009-of-00014.safetensors:  13% 126M/990M [00:02<00:29, 29.2MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  16% 157M/990M [00:02<00:17, 46.3MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  18% 178M/990M [00:02<00:14, 55.5MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  20% 199M/990M [00:02<00:11, 67.8MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  23% 231M/990M [00:03<00:08, 92.4MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  26% 262M/990M [00:03<00:06, 116MB/s] \u001b[A\n",
            "model-00009-of-00014.safetensors:  29% 283M/990M [00:03<00:05, 129MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  31% 304M/990M [00:03<00:05, 130MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  33% 325M/990M [00:03<00:04, 142MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  36% 357M/990M [00:03<00:03, 162MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  39% 388M/990M [00:03<00:03, 183MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  42% 419M/990M [00:04<00:02, 195MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  46% 451M/990M [00:04<00:02, 200MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  49% 482M/990M [00:04<00:02, 204MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  52% 514M/990M [00:04<00:02, 215MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  55% 545M/990M [00:04<00:02, 217MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  58% 577M/990M [00:04<00:01, 214MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  61% 608M/990M [00:04<00:01, 213MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  65% 640M/990M [00:05<00:01, 182MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  67% 661M/990M [00:08<00:12, 26.0MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  69% 682M/990M [00:08<00:10, 30.5MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  72% 713M/990M [00:08<00:06, 43.6MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  75% 744M/990M [00:08<00:04, 59.6MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  78% 776M/990M [00:09<00:02, 78.5MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  81% 797M/990M [00:09<00:02, 91.4MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  83% 818M/990M [00:09<00:01, 103MB/s] \u001b[A\n",
            "model-00009-of-00014.safetensors:  85% 839M/990M [00:09<00:01, 116MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  88% 870M/990M [00:09<00:00, 143MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  91% 902M/990M [00:09<00:00, 165MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  94% 933M/990M [00:09<00:00, 185MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  97% 965M/990M [00:09<00:00, 188MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors: 100% 990M/990M [00:10<00:00, 97.9MB/s]\n",
            "Downloading shards:  64% 9/14 [01:16<00:45,  9.14s/it]\n",
            "model-00010-of-00014.safetensors:   0% 0.00/944M [00:00<?, ?B/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:   3% 31.5M/944M [00:00<00:04, 224MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:   7% 62.9M/944M [00:00<00:04, 209MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  10% 94.4M/944M [00:00<00:03, 214MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  13% 126M/944M [00:00<00:03, 217MB/s] \u001b[A\n",
            "model-00010-of-00014.safetensors:  17% 157M/944M [00:00<00:03, 222MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  20% 189M/944M [00:00<00:03, 216MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  23% 220M/944M [00:01<00:03, 212MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  27% 252M/944M [00:01<00:03, 204MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  29% 273M/944M [00:01<00:03, 203MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  31% 294M/944M [00:01<00:03, 205MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  33% 315M/944M [00:01<00:03, 188MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  36% 336M/944M [00:01<00:03, 177MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  38% 357M/944M [00:01<00:03, 163MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  40% 377M/944M [00:01<00:03, 162MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  42% 398M/944M [00:02<00:03, 161MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  44% 419M/944M [00:02<00:03, 162MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  47% 440M/944M [00:03<00:08, 58.2MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  50% 472M/944M [00:03<00:05, 81.7MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  52% 493M/944M [00:03<00:05, 84.8MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  54% 514M/944M [00:03<00:04, 101MB/s] \u001b[A\n",
            "model-00010-of-00014.safetensors:  58% 545M/944M [00:03<00:03, 127MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  61% 577M/944M [00:03<00:02, 151MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  63% 598M/944M [00:03<00:02, 158MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  66% 619M/944M [00:04<00:02, 159MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  68% 640M/944M [00:04<00:01, 169MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  71% 671M/944M [00:04<00:01, 179MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  73% 692M/944M [00:05<00:05, 43.7MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  76% 713M/944M [00:05<00:04, 55.3MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  78% 734M/944M [00:06<00:03, 69.4MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  81% 765M/944M [00:06<00:01, 94.1MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  84% 797M/944M [00:06<00:01, 118MB/s] \u001b[A\n",
            "model-00010-of-00014.safetensors:  87% 818M/944M [00:06<00:00, 129MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  89% 839M/944M [00:06<00:00, 133MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  91% 860M/944M [00:06<00:00, 147MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  94% 891M/944M [00:06<00:00, 168MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  97% 912M/944M [00:07<00:00, 154MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors: 100% 944M/944M [00:07<00:00, 131MB/s]\n",
            "Downloading shards:  71% 10/14 [01:23<00:34,  8.58s/it]\n",
            "model-00011-of-00014.safetensors:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:   3% 31.5M/990M [00:00<00:04, 235MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:   6% 62.9M/990M [00:00<00:03, 241MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  10% 94.4M/990M [00:00<00:03, 246MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  13% 126M/990M [00:00<00:03, 234MB/s] \u001b[A\n",
            "model-00011-of-00014.safetensors:  16% 157M/990M [00:00<00:03, 208MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  19% 189M/990M [00:00<00:03, 212MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  22% 220M/990M [00:01<00:03, 210MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  25% 252M/990M [00:01<00:03, 186MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  28% 273M/990M [00:01<00:03, 186MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  31% 304M/990M [00:01<00:03, 198MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  34% 336M/990M [00:01<00:03, 202MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  36% 357M/990M [00:01<00:03, 198MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  38% 377M/990M [00:01<00:03, 198MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  40% 398M/990M [00:01<00:03, 191MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  42% 419M/990M [00:02<00:02, 194MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  44% 440M/990M [00:02<00:02, 193MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  47% 461M/990M [00:02<00:02, 195MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  50% 493M/990M [00:02<00:02, 209MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  53% 524M/990M [00:02<00:02, 207MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  55% 545M/990M [00:02<00:02, 188MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  57% 566M/990M [00:02<00:02, 184MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  60% 598M/990M [00:02<00:01, 199MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  64% 629M/990M [00:03<00:01, 211MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  67% 661M/990M [00:03<00:01, 208MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  69% 682M/990M [00:03<00:01, 200MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  71% 703M/990M [00:03<00:01, 200MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  74% 734M/990M [00:03<00:01, 202MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  77% 765M/990M [00:03<00:01, 206MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  79% 786M/990M [00:03<00:01, 193MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  82% 807M/990M [00:05<00:05, 36.2MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  84% 828M/990M [00:06<00:03, 40.9MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  86% 849M/990M [00:06<00:02, 52.0MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  88% 870M/990M [00:06<00:01, 64.9MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  90% 891M/990M [00:06<00:01, 80.9MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  92% 912M/990M [00:06<00:00, 97.6MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  94% 933M/990M [00:06<00:00, 116MB/s] \u001b[A\n",
            "model-00011-of-00014.safetensors:  97% 965M/990M [00:06<00:00, 140MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors: 100% 990M/990M [00:07<00:00, 140MB/s]\n",
            "Downloading shards:  79% 11/14 [01:30<00:24,  8.16s/it]\n",
            "model-00012-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:   2% 21.0M/967M [00:00<00:06, 142MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:   4% 41.9M/967M [00:00<00:06, 142MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:   7% 62.9M/967M [00:00<00:05, 154MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:   9% 83.9M/967M [00:00<00:05, 171MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  12% 115M/967M [00:00<00:04, 197MB/s] \u001b[A\n",
            "model-00012-of-00014.safetensors:  14% 136M/967M [00:00<00:04, 199MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  17% 168M/967M [00:00<00:03, 209MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  21% 199M/967M [00:01<00:03, 216MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  24% 231M/967M [00:01<00:03, 222MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  27% 262M/967M [00:01<00:03, 221MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  30% 294M/967M [00:01<00:02, 228MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  34% 325M/967M [00:01<00:02, 235MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  37% 357M/967M [00:01<00:02, 223MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  40% 388M/967M [00:01<00:02, 212MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  43% 419M/967M [00:02<00:02, 212MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  47% 451M/967M [00:02<00:04, 112MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  49% 472M/967M [00:03<00:08, 56.8MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  51% 493M/967M [00:03<00:06, 68.5MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  53% 514M/967M [00:03<00:05, 76.9MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  55% 535M/967M [00:04<00:04, 87.9MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  59% 566M/967M [00:04<00:03, 112MB/s] \u001b[A\n",
            "model-00012-of-00014.safetensors:  62% 598M/967M [00:04<00:02, 133MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  64% 619M/967M [00:04<00:02, 134MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  66% 640M/967M [00:04<00:02, 144MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  69% 671M/967M [00:04<00:01, 163MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  73% 703M/967M [00:04<00:01, 184MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  76% 734M/967M [00:05<00:01, 193MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  78% 755M/967M [00:05<00:01, 194MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  80% 776M/967M [00:05<00:00, 197MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  82% 797M/967M [00:05<00:00, 199MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  85% 818M/967M [00:05<00:00, 201MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  87% 839M/967M [00:06<00:01, 90.0MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  89% 860M/967M [00:07<00:03, 30.9MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  92% 891M/967M [00:07<00:01, 45.7MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  94% 912M/967M [00:08<00:01, 54.2MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  97% 933M/967M [00:08<00:00, 66.5MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors: 100% 967M/967M [00:08<00:00, 115MB/s] \n",
            "Downloading shards:  86% 12/14 [01:39<00:16,  8.27s/it]\n",
            "model-00013-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:   2% 21.0M/967M [00:00<00:05, 170MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:   5% 52.4M/967M [00:00<00:04, 202MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:   9% 83.9M/967M [00:00<00:04, 216MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  12% 115M/967M [00:00<00:03, 221MB/s] \u001b[A\n",
            "model-00013-of-00014.safetensors:  15% 147M/967M [00:00<00:03, 211MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  18% 178M/967M [00:00<00:03, 209MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  21% 199M/967M [00:00<00:03, 206MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  24% 231M/967M [00:01<00:03, 207MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  26% 252M/967M [00:01<00:03, 207MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  29% 283M/967M [00:01<00:03, 211MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  33% 315M/967M [00:01<00:03, 213MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  36% 346M/967M [00:01<00:02, 218MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  39% 377M/967M [00:01<00:02, 216MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  42% 409M/967M [00:01<00:02, 206MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  44% 430M/967M [00:02<00:02, 206MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  47% 451M/967M [00:02<00:02, 201MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  50% 482M/967M [00:02<00:02, 206MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  52% 503M/967M [00:02<00:02, 197MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  54% 524M/967M [00:02<00:02, 181MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  56% 545M/967M [00:02<00:02, 166MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  59% 566M/967M [00:02<00:02, 165MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  61% 587M/967M [00:02<00:02, 167MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  63% 608M/967M [00:03<00:04, 75.2MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  65% 629M/967M [00:05<00:10, 33.7MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  67% 650M/967M [00:05<00:07, 44.2MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  69% 671M/967M [00:05<00:05, 54.8MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  72% 692M/967M [00:05<00:04, 67.4MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  75% 724M/967M [00:05<00:02, 92.8MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  77% 744M/967M [00:05<00:02, 109MB/s] \u001b[A\n",
            "model-00013-of-00014.safetensors:  80% 776M/967M [00:05<00:01, 127MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  82% 797M/967M [00:06<00:01, 133MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  85% 818M/967M [00:06<00:01, 144MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  88% 849M/967M [00:06<00:00, 168MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  90% 870M/967M [00:06<00:00, 172MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  92% 891M/967M [00:06<00:00, 170MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  94% 912M/967M [00:06<00:00, 178MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  98% 944M/967M [00:06<00:00, 197MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors: 100% 967M/967M [00:06<00:00, 139MB/s]\n",
            "Downloading shards:  93% 13/14 [01:46<00:07,  7.91s/it]\n",
            "model-00014-of-00014.safetensors:   0% 0.00/847M [00:00<?, ?B/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:   2% 21.0M/847M [00:00<00:04, 188MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:   5% 41.9M/847M [00:00<00:04, 197MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:   9% 73.4M/847M [00:00<00:03, 209MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  11% 94.4M/847M [00:01<00:18, 40.1MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  14% 115M/847M [00:03<00:27, 26.3MB/s] \u001b[A\n",
            "model-00014-of-00014.safetensors:  17% 147M/847M [00:03<00:16, 41.2MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  20% 168M/847M [00:03<00:13, 50.4MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  22% 189M/847M [00:03<00:10, 62.8MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  26% 220M/847M [00:03<00:07, 87.1MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  30% 252M/847M [00:03<00:05, 111MB/s] \u001b[A\n",
            "model-00014-of-00014.safetensors:  32% 273M/847M [00:03<00:04, 117MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  35% 294M/847M [00:04<00:04, 128MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  38% 325M/847M [00:04<00:03, 153MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  42% 357M/847M [00:04<00:02, 170MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  45% 377M/847M [00:04<00:03, 126MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  48% 409M/847M [00:04<00:02, 150MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  52% 440M/847M [00:04<00:02, 170MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  56% 472M/847M [00:05<00:01, 188MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  59% 503M/847M [00:05<00:01, 202MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  63% 535M/847M [00:05<00:01, 202MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  67% 566M/847M [00:05<00:01, 194MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  71% 598M/847M [00:05<00:01, 200MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  74% 629M/847M [00:05<00:01, 201MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  78% 661M/847M [00:05<00:00, 213MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  82% 692M/847M [00:06<00:00, 220MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  85% 724M/847M [00:06<00:00, 200MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  88% 744M/847M [00:06<00:00, 191MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  92% 776M/847M [00:06<00:00, 198MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  94% 797M/847M [00:06<00:00, 194MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  97% 818M/847M [00:06<00:00, 185MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors: 100% 847M/847M [00:06<00:00, 122MB/s]\n",
            "Downloading shards: 100% 14/14 [01:53<00:00,  8.09s/it]\n",
            "Loading checkpoint shards: 100% 14/14 [01:03<00:00,  4.51s/it]\n",
            "generation_config.json: 100% 132/132 [00:00<00:00, 717kB/s]\n",
            "> \u001b[1mINFO    creating trainer\u001b[0m\n",
            "Generating train split: 0 examples [00:00, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2901 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Generating train split: 2131 examples [00:09, 225.57 examples/s]\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:294: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "  0% 0/2132 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "  5% 98/2132 [27:24<9:29:33, 16.80s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 작은 모델로 체크\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"aboonaji/alpaca_micro_demo\")\n",
        "dataset"
      ],
      "metadata": {
        "id": "KRlriWUPZ8yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "m_bcDZWUaKAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2-_lkBS1WKA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "#@markdown Note: if you are using a restricted/private model, you need to enter your Hugging Face token in the next step.\n",
        "project_name = 'my_autotrain_llm' # @param {type:\"string\"}\n",
        "model_name = 'abhishek/llama-2-7b-hf-small-shards' # @param {type:\"string\"}\n",
        "# data_path = 'royboy0416/ko-alpaca' # @param {type:\"string\"}\n",
        "data_path = 'aboonaji/alpaca_micro_demo' # @param {type:\"string\"}\n",
        "text_column = 'text' # @param {type:\"string\"}\n",
        "# royboy0416/ko-alpaca, timdettmers/openassistant-guanaco\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "repo_id = \"keepsteady/autotrain_test\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "#@markdown ###### A100: 16, T4: 2\n",
        "num_train_epochs = 1 #@param {type:\"number\"}\n",
        "learning_rate = 2e-4 # @param {type:\"number\"}\n",
        "train_batch_size = 2 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "block_size = 1024 # @param {type:\"number\"}\n",
        "trainer = \"sft\" # @param [\"default\", \"sft\"] {type:\"raw\"}\n",
        "warmup_ratio = 0.1 # @param {type:\"number\"}\n",
        "weight_decay = 0.01 # @param {type:\"number\"}\n",
        "gradient_accumulation_step = 4 # @param {type:\"number\"}\n",
        "use_fp16 = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_peft = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_merge_adapter = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_int4 = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "lora_r = 16 #@param {type:\"number\"}\n",
        "lora_alpha = 32 #@param {type:\"number\"}\n",
        "lora_dropout = 0.05 #@param {type:\"number\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"REPO_ID\"] = repo_id\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_EPOCHS\"] = str(num_train_epochs)\n",
        "os.environ[\"BATCH_SIZE\"] = str(train_batch_size)\n",
        "os.environ[\"BLOCK_SIZE\"] = str(block_size)\n",
        "os.environ[\"WARMUP_RATIO\"] = str(warmup_ratio)\n",
        "os.environ[\"WEIGHT_DECAY\"] = str(weight_decay)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation_step)\n",
        "os.environ[\"USE_FP16\"] = str(use_fp16)\n",
        "os.environ[\"USE_PEFT\"] = str(use_peft)\n",
        "os.environ[\"USE_INT4\"] = str(use_int4)\n",
        "os.environ[\"LORA_R\"] = str(lora_r)\n",
        "os.environ[\"LORA_ALPHA\"] = str(lora_alpha)\n",
        "os.environ[\"LORA_DROPOUT\"] = str(lora_dropout)\n",
        "\n",
        "\n",
        "\n",
        "txt_fp16 = ' --fp16' if use_fp16 else ''\n",
        "txt_use_peft = ' --use_peft' if use_peft else ''\n",
        "txt_use_int4 = ' --use_int4' if use_int4 else ''\n",
        "txt_use_merge_adapter = ' --merge_adapter' if use_merge_adapter else ''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train!\n",
        "cmd = f'!autotrain llm \\\n",
        "--train \\\n",
        "--model \"{model_name}\" \\\n",
        "--project_name \"{project_name}\" \\\n",
        "--data_path \"{data_path}\" \\\n",
        "--text_column \"{text_column}\" \\\n",
        "--learning_rate {learning_rate} \\\n",
        "--train_batch_size {train_batch_size} \\\n",
        "--num_train_epochs {num_train_epochs} \\\n",
        "--block_size {block_size} \\\n",
        "--warmup_ratio {warmup_ratio} \\\n",
        "--lora_r {lora_r} \\\n",
        "--lora_alpha {lora_alpha} \\\n",
        "--lora_dropout {lora_dropout} \\\n",
        "--weight_decay {weight_decay} \\\n",
        "--gradient_accumulation_steps {gradient_accumulation_step} \\\n",
        "--trainer {trainer} \\\n",
        "{txt_fp16}{txt_use_peft}{txt_use_int4}{txt_use_merge_adapter} \\\n",
        "--push-to-hub --token \"{hf_token}\" --repo-id \"{repo_id}\"'\n",
        "\n",
        "print(cmd)\n",
        "!$command"
      ],
      "metadata": {
        "id": "S0eoLB0JaVdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1o9UOaZXaYS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3XZKnC03LUk"
      },
      "outputs": [],
      "source": [
        "!autotrain llm --train --model \"abhishek/llama-2-7b-hf-small-shards\" --project_name \"my_autotrain_llm\" --data_path \"aboonaji/alpaca_micro_demo\" --text_column \"text\" --learning_rate 0.0002 --train_batch_size 2 --num_train_epochs 1 --block_size 1024 --warmup_ratio 0.1 --lora_r 16 --lora_alpha 32 --lora_dropout 0.05 --weight_decay 0.01 --gradient_accumulation_steps 4 --trainer sft  --fp16 --use_peft --use_int4 --merge_adapter --push-to-hub --token \"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\" --repo-id \"keepsteady/autotrain_test\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id = 'keepsteady/autotrain_test'"
      ],
      "metadata": {
        "id": "sV8GiEebaqvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "model_id = \"TinyPixel/Llama-2-7B-bf16-sharded\"\n",
        "# # 구글드라이브에서 가져오기\n",
        "# peft_model_id = \"/content/drive/MyDrive/my_autotrain_llm/checkpoint-1222\"  # checkpoint 변경\n",
        "# # huggingface에서 가져오기\n",
        "# peft_model_id = 'keepsteady/autotrain_test'  # 학습 저장된 폴더경로\n",
        "# local에 저장된 폴더에서 모델 가져오기\n",
        "peft_model_id = './my_autotrain_llm/checkpoint-5'\n",
        "\n",
        "\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "\n",
        "\n",
        "# Huggingface에 저장된 README.md 에서 Training porcedure 값을 가져옴\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=False,\n",
        "    load_in_4bit=True,\n",
        "    llm_int8_threshold=6.0,\n",
        "    llm_int8_skip_modules=None,\n",
        "    llm_int8_enable_fp32_cpu_offload=False,\n",
        "    llm_int8_has_fp16_weight=False,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=False,\n",
        "    bnb_4bit_compute_dtype=\"float16\",\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "model.eval()\n",
        "print('load model complete')"
      ],
      "metadata": {
        "id": "-n6PhAJ4cfRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data\n",
        "description = 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.'\n",
        "\n",
        "\n",
        "지시 = 'Identify the odd one out.'\n",
        "입력 = 'Twitter, Instagram, Telegram'\n",
        "출력 = 'Telegram'\n",
        "\n",
        "text = f'{description}\\n### Instruction: {지시}\\n### Input: {입력}\\n### Response: {출력}'\n",
        "print(text)\n"
      ],
      "metadata": {
        "id": "SHvIqhLgctpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "llama_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "id": "TQNcoEzRcww-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen(Instruction=None, Input=None):\n",
        "\n",
        "    # 포맷 변경\n",
        "    description = 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.'\n",
        "    if Input:\n",
        "        prompt = f'{description}\\n### Instruction: {Instruction}\\n### Input: {Input}\\n### Response: '\n",
        "    else:\n",
        "        prompt = f'{description}\\n### Instruction: {Instruction}\\n### Response: '\n",
        "\n",
        "    generated_txt = model.generate(\n",
        "        **tokenizer(\n",
        "            prompt,  # 프롬프트 입력\n",
        "            return_tensors='pt',\n",
        "            return_token_type_ids=False\n",
        "        ).to('cuda'),\n",
        "        max_new_tokens=128,\n",
        "        early_stopping=True,\n",
        "        do_sample=True,\n",
        "    )\n",
        "    answer = tokenizer.decode(generated_txt[0]).replace(prompt, \"\").lstrip('<s> ').rstrip('</s>').strip().split(\"\\n### \")[0].strip()\n",
        "    print(answer)\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "output = gen(Instruction=\"생성형 AI로 업무를 자동화 할 수 있을까요?\", Input=None)"
      ],
      "metadata": {
        "id": "9QOTfy4Kczzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = gen(Instruction=\"AI를 실제 업무에 적용하려면 어떤 프로세스가 필요해요?\", Input=None)"
      ],
      "metadata": {
        "id": "gmIJ-ZGuc27Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}